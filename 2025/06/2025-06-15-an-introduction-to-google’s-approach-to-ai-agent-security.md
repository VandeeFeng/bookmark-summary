# An Introduction to Google’s Approach to AI Agent Security
- URL: https://simonwillison.net/2025/Jun/15/ai-agent-security/
- Added At: 2025-06-15 08:08:38
- [Link To Text](2025-06-15-an-introduction-to-google’s-approach-to-ai-agent-security_raw.md)

## Summary
**摘要**：  
这篇文章介绍了谷歌关于AI代理安全的框架，重点关注两大核心风险：**恶意行为**（未授权、有害或违反政策的操作）和**敏感数据泄露**（未经授权披露私人信息）。谷歌提出三个核心原则来应对这些风险：明确界定人类控制者、限制代理权限、确保代理行为的可观察性和可审计性。文章还详细讨论了谷歌的混合防御策略，包括传统的确定性措施（如运行时策略执行）和基于推理的动态防御（如对抗训练和专用防护模型），并指出后者虽然能补充传统方法，但无法提供绝对安全保障。作者对动态防御的实际效果持怀疑态度，认为确定性措施更为可靠。

**要点总结**：  
1. **两大核心风险**：  
   谷歌指出AI代理的主要安全风险是恶意行为（如未授权操作）和敏感数据泄露。恶意行为常由提示注入攻击引发，而数据泄露则通过代理的副作用（如URL嵌入敏感信息）实现。

2. **核心安全原则**：  
    - 明确人类控制者：代理需在授权用户监督下运行，关键操作需人工确认。  
    - 限制代理权限：代理的权限应动态调整，避免不必要的资源访问。  
    - 可观察性：代理的行为和决策过程必须透明，便于审计和发现潜在问题。  

3. **混合防御策略**：  
   谷歌结合传统确定性措施（如策略引擎拦截高风险操作）和基于AI的推理防御（如对抗训练）。前者更可靠，后者则用于补充传统方法的局限性，但无法提供绝对安全保证。  

4. **对动态防御的质疑**：  
   作者对基于AI的推理防御（如防护模型）的有效性持保留态度，认为其无法彻底解决提示注入等新型攻击，强调确定性措施仍是安全基石。
