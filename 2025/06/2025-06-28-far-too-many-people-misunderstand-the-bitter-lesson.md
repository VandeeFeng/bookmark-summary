# Far too many people misunderstand the bitter lesson
- URL: https://www.artfintel.com/p/the-bitter-lesson
- Added At: 2025-06-28 03:26:10
- [Link To Text](2025-06-28-far-too-many-people-misunderstand-the-bitter-lesson_raw.md)

## Summary
**摘要**：
《苦乐教训》一文的核心观点是，长期来看，能有效利用计算资源的算法终将胜过依赖人工知识的算法。这一教训被称为"苦涩"，因为短期内依赖人工知识往往能快速获得成果，但最终会陷入发展瓶颈。文章通过计算机象棋和围棋的历史案例说明，尽管专家系统和启发式方法在特定时期表现优异（如深蓝的国际象棋系统和早期的围棋程序），但最终被基于大规模计算和学习的通用方法（如AlphaGo Zero）超越。作者指出，AI领域的历史规律表明：研究者倾向于构建人工知识系统获得短期成就感，但这会阻碍长期突破；真正的进步来自于利用计算规模的搜索和学习方法。当前大型语言模型的发展也面临类似抉择：专注于特定基准测试的人工优化还是提升模型的通用能力。

**要点总结**：
1. **计算规模的重要性**：算法发展的长期胜出者都是能随计算资源扩展而提升效果的方法，因为计算能力持续呈数量级增长，而其他资源增长有限。历史证明依赖固定人工知识的方法终将被更具扩展性的方法超越。
2. **短期收益与长期代价**：将人工知识（如专家系统、手工特征）融入AI系统能在短期内快速提升性能，这在博弈程序发展史（从深蓝到AlphaGo）中反复验证，但这种改进存在性能天花板，最终阻碍根本性突破。
3. **技术转型的阻力机制**：即使新的范式已证明优越性（如深蓝成功后），旧范式仍会持续多年，这与学术职业周期（博士培养、职称晋升）和组织惯性有关，形成"一个时代结束需要机构重组"的转型模式。
4. **当前AI研发的实践启示**：在大型语言模型竞争中，专注于特定基准测试的短期优化（人工数据/规则）虽能快速提升指标，但投资通用能力（合成数据、混合专家模型等可扩展方法）才是长期制胜关键，NVIDIA硬件发展将为此提供支撑。
