# S1: The $6 R1 Competitor?
- URL: https://simonwillison.net/2025/Feb/5/s1-the-6-r1-competitor/
- Added At: 2025-02-07 05:57:56
- [Link To Text](2025-02-07-s1-the-$6-r1-competitor_raw.md)

## Summary
**摘要**:
这篇文章讨论了一篇题为《s1: Simple test-time scaling》的论文,文章描述了在Qwen2.5-32B-Instruct顶上进行调优的推理尺度化模型,仅需$6的预算,就能够实现对32B模型的性能提升。作者Tim Kellogg分享了这个实验的重点成果:经过削减后的56000个例子中最好的1000个就足够实现与32B模型相媲美的o1-preview性能。论文中提到的技术叫做“Budget forcing”,旨在通过抑制思考结束符的生成并增加等效的“Wait”字符串来鼓励模型自我反思。作者自建了一个Hugging Face上s1-32B模型以及配套的1000个样本数据集,并通过利用工具(如Ollama和DuckDB)进行数据处理和分析,最终体现出该模型在数学和科学领域的应用,其中包括15个作为示例的填字游戏题目。

**要点总结**:
- **成本效益:** 研究通过低成本($6)覆盖16个NVIDIA H100 GPU小时,展示了构建高性能推理模型的可能性。
- **简单训练数据集:** 通过对大量数据集的削减(56K到K级),模型仍能获取关键信息并达到显著性能。
- **Budget forcing技术:** 提出的策略利用自省机制来优化模型性能,通过抑制某特定标记符的生成,增加鼓励深思熟虑的信息。
- **案例验证:** 包含数学、科学领域的具体应用实例(例如填字游戏题目),展示模型在不同任务上的适应性与效果。
- **数据资源的获取与分析:** 整体流程从论文到模型资源、数据集的获取,及通过编程工具(DuckDB、sqlite-utils或Ollama)实现的数据处理和可视化分析,充分展现了跨领域数据应用的可行性。
