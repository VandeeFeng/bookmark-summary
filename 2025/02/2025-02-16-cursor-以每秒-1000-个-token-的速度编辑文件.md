# Cursor: 以每秒 1000 个 Token 的速度编辑文件
- URL: https://baoyu.io/translations/cursor-editing-1000-tokens-per-second
- Added At: 2025-02-16 08:49:25
- [Link To Text](2025-02-16-cursor-以每秒-1000-个-token-的速度编辑文件_raw.md)

## Summary
**摘要**：
本文介绍了一种新的模型和推理方法，旨在以每秒 1000 个 token 的速度实现对整个文件的高精度编辑，尤其是在代码编辑任务中。当前的大型模型（如 GPT-4o）在处理大规模编辑时存在懒惰、不准确和高延迟等问题。作者专门针对全文件代码编辑任务训练了一个名为 "fast apply" 的模型，将编辑过程分为规划和应用两个阶段，其中“规划”阶段通过强大的前沿模型聊天界面完成，而“应用”阶段则通过 fast-apply 模型实现快速修改。该模型在准确性和速度上均超越了 GPT-4 和 GPT-4o，通过使用专门为代码编辑场景定制的 speculative edits (推测式编辑) 变体进行推理，达到了约 1000 tokens/s 的速度，实现了约 13 倍的加速。该模型通过重写整个文件而非输出 diff 来避免了语言模型在处理 diff 格式时遇到的困难，作者还分享了构建评估集、速度测量方法以及模型训练的细节。最后，文章还探讨了未来研究方向，包括长上下文训练、知识蒸馏以及进一步提高准确率，并介绍了推测式编辑在提高模型速度上的巨大作用。

**要点总结**：

1.  **提出了Fast Apply模型解决代码编辑难题**：为了解决现有模型在代码编辑中存在的问题，作者专门训练了一个名为 Fast Apply 的模型，该模型能够以高精度、低延迟的方式对整个文件进行编辑，尤其擅长处理大规模的代码修改任务。
2.  **采用推测式编辑大幅提升速度**：通过采用自研的推测式解码算法 speculative edits，模型在速度上获得了显著提升，达到了最高 9 倍的加速效果，使得 Llama-3 在 speculative edits 的加持下，速度能够达到现有最快模型的 4-5 倍。Speculative edits 是一种通过确定性算法对未来 token 进行推测的技术，特别适用于代码编辑场景。
3.  **全文件重写策略优于Diff模型**：文章解释了为什么让模型重写整个文件，而不是输出 diff 格式。主要原因在于，语言模型在处理 diff 格式时往往遇到困难，可能是因为 diff 格式提供的“思考 Token”较少，或者 diff 格式与模型预训练时接触的数据分布差异较大，以及输出行号带来的挑战。
4.  **数据合成和模型训练技巧**：为了训练 fast-apply 模型，文章采取了包括合成数据在内的一系列策略，同时在 Deepseek Coder Instruct 和 Llama 3 模型系列上进行微调，并通过对训练数据进行降采样等处理，进一步完善训练集，最终得到了性能优异的 Llama-3-70b-ft 模型。

