# LLM Powered Autonomous Agents
- URL: https://lilianweng.github.io/posts/2023-06-23-agent/
- Added At: 2025-03-23 10:00:28
- [Link To Text](2025-03-23-llm-powered-autonomous-agents_raw.md)

## Summary
**摘要**：
本文探讨了如何利用大型语言模型（LLM）构建自主代理，并概述了LLM驱动的自主代理系统的关键组成部分。这些组件包括规划（将大型任务分解为子目标，并通过反思改进）、记忆（短期记忆利用上下文学习，长期记忆利用外部向量存储和快速检索）和工具使用（学习调用外部API以获取模型权重中缺失的信息）。文章深入研究了规划组件，包括任务分解（如Chain of Thought和Tree of Thoughts）和自我反思（如ReAct和Reflexion）。还探讨了记忆的类型，如感觉记忆、短期记忆和长期记忆，以及用于快速最大内积搜索（MIPS）的常见近似最近邻（ANN）算法。文章还讨论了工具的使用，包括MRKL、TALM和Toolformer，以及ChatGPT插件和OpenAI API函数调用等实际应用。此外，还介绍了HuggingGPT和API-Bank等框架和基准，用于评估工具增强的LLM的性能。最后，通过科学发现代理和生成代理模拟等案例研究，展示了LLM驱动的自主代理的潜力，并探讨了AutoGPT和GPT-Engineer等概念验证示例，同时也指出了有限的上下文长度、长期规划和任务分解的挑战以及自然语言接口的可靠性等局限性。

**要点总结**：

1.  **LLM驱动的自主代理系统**：该系统以LLM为核心，通过规划、记忆和工具使用三大组件协同工作。规划涉及任务分解和自我反思，记忆分为短期（上下文学习）和长期（外部向量存储），工具使用则是调用外部API获取信息。
2.  **规划能力**：文章介绍了多种任务分解方法，包括Chain of Thought (CoT)促使模型逐步思考，将复杂任务拆解为更小的步骤；Tree of Thoughts (ToT)则进一步扩展CoT，在每一步探索多种推理可能性，形成树状结构，便于搜索最优解。此外，还讨论了通过ReAct框架将推理和行动相结合，使LLM能够与环境互动并生成自然语言推理轨迹。
3.  **记忆机制**：模仿人脑的记忆模式，代理的记忆分为感觉记忆（原始输入的嵌入表示）、短期记忆（上下文学习，受Transformer限制）和长期记忆（外部向量存储，支持快速检索）。为了优化检索速度，通常采用近似最近邻（ANN）算法，如LSH、ANNOY、HNSW、FAISS和ScaNN等，以实现快速最大内积搜索（MIPS）。
4.  **工具使用**：LLM可以通过调用外部API来扩展自身能力，弥补模型权重中的信息缺失。MRKL是一种神经符号架构，利用LLM作为路由器，将查询导向最合适的专家模块（可以是神经网络或符号工具）。HuggingGPT则利用ChatGPT作为任务规划器，从Hugging Face平台选择合适的模型来执行任务，并总结结果。API-Bank则提供了一个基准，用于评估工具增强型LLM的性能，包含各种API工具和带注释的对话，涵盖API调用、检索和规划等多个层次。
5.  **案例与挑战**：文章通过ChemCrow展示了LLM在科学发现领域的应用，通过Generative Agents模拟了由LLM驱动的虚拟角色在沙盒环境中的互动。AutoGPT和GPT-Engineer等项目展示了自主代理的潜力。同时也指出了有限的上下文长度、长期规划和任务分解的挑战以及自然语言接口的可靠性等局限性。

