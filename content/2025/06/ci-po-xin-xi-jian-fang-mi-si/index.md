---
title: 刺破信息茧房迷思
date: 2025-06-03
extra:
  source: https://www.orangeclk.com/2021/06/07/information-cocoons-myth/
  original_title: 刺破信息茧房迷思
---
## Summary
**摘要**：
文章探讨了“信息茧房”这一概念的起源与在当下互联网环境中的误解。最初由桑斯坦在《信息乌托邦》中提出，指人们只选择与自己观点一致的信息，可能导致决策失误。然而，在推荐算法主导的现代互联网时代，这一概念实际已演变为对推荐系统和社交网络导致信息窄化的担忧，学界更常用“过滤气泡”和“回音室效应”来描述这种现象。文章引用2018年发表在PNAS上的研究，通过Twitter机器人实验发现，接触对立观点反而加剧了政治极化，与“回音室”假说相反。作者指出，当前中文互联网对“信息茧房”的讨论多停留于概念化层面，缺乏实证支持，可能误导公众和监管决策，呼吁更理性地分析技术的影响。

**要点总结**：
1. **信息茧房概念的演变**：桑斯坦最初定义的信息茧房强调个体主动选择信息导致的信息窄化，但在推荐算法时代，实际讨论的是算法主导的信息过滤现象，学界更倾向于使用“过滤气泡”和“回音室效应”等术语。
2. **实证研究的发现**：2018年PNAS的研究通过Twitter机器人实验证明，接触对立政治观点并不会缓和立场，反而会加剧极化，这与“回音室效应”的假说相反，表明信息环境的影响机制可能比理论假设更复杂。
3. **中文互联网的误解**：中文世界对“信息茧房”的讨论多基于望文生义的概念化理解，缺乏实证支持，且常将算法推荐技术与信息窄化简单关联，忽略了技术可能带来的信息广度扩展。
4. **监管与学术的鸿沟**：公众和部分专家对“信息茧房”的误解可能影响监管决策，作者呼吁基于实证研究理性分析技术的影响，避免因错误认知制定过度限制性的政策。
5. **技术评价的视角**：作者强调应从动态发展的角度评估新技术，避免以过去为标杆的刻板对比，而应关注技术如何塑造信息生态，平衡其利弊。
## Full Content
Title: 刺破信息茧房迷思

URL Source: https://www.orangeclk.com/2021/06/07/information-cocoons-myth/

Published Time: 2021-06-06T16:23:12.000Z

Markdown Content:
**文章目录**

1.   [1.概念](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E6%A6%82%E5%BF%B5)
2.   [2.论文](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AE%BA%E6%96%87)
    1.   [2.1.Exposure to opposing views on social media can increase political polarization](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#Exposure-to-opposing-views-on-social-media-can-increase-political-polarization)
        1.   [2.1.1.Twitter机器人的转发机制](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#Twitter%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E8%BD%AC%E5%8F%91%E6%9C%BA%E5%88%B6)
        2.   [2.1.2.被试配合度](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%A2%AB%E8%AF%95%E9%85%8D%E5%90%88%E5%BA%A6)
        3.   [2.1.3.试验结果](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AF%95%E9%AA%8C%E7%BB%93%E6%9E%9C)

3.   [3.评述](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AF%84%E8%BF%B0)

[](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E6%A6%82%E5%BF%B5 "概念")概念
--------------------------------------------------------------------------------------------

在说概念之前，我想说的是，名字不重要，重要是实质。

信息茧房究竟是指什么呢？这个词是桑斯坦在 _Infotopia_（《信息乌托邦》）这本书里提出的，我将原文翻译如下：

> 在互联网的早期，麻省理工学院的传媒与科技专家尼古拉斯·尼葛洛庞帝（Nicholas Negroponte）就预言了“the Daily Me（我的日报）”的出现。the Daily Me是一种完全个性化的报纸，每个人都可以挑选自己喜欢的话题和观点呈现到报纸上。对于一些人而言，the Daily Me是巨大的机会，但也可能是巨大的风险；对于商业和民主而言，the Daily Me也偶尔会带来不幸。核心问题是信息茧房（information cocoons）：在茧房里，我们只能听到我们自己选择的内容、让我们舒适的内容、取悦我们的内容。
> 
> 如果一家公司创造了信息茧房，它就不太可能繁荣，因为它自己的决定不会受到来自内部的充分挑战，一些公司就是因为这个原因而失败的。如果政治团体或国家领导人生活在茧房中，他们就不太可能有好的想法，他们自己的成见会变得根深蒂固，一些国家因为这个原因而陷入灾难。对于领导人（其他人也一样）来说，生活在信息茧房中是舒适的——那里温暖而友好，所有人都认可自己的观点。但是，舒适的代价会是重大的错误。对于私人和公共机构来说，茧房可以变成可怕的恶梦。

总结来看，桑斯坦这里说的“信息茧房”更加接近于花剌子模的信使那个故事，讲的是人或者组织只接受自己选择的、让自己舒适的信息，会让人或组织难以做出正确决策。

他在探讨这个比喻的时候，是在讨论美国政治的语境之下。他的比喻也强调用户对信息的自主筛选、选择。

![Image 1: Infotopia](https://img.orangeclk.com/information-cocoons-myth/infotopia.jpg)

在Google Scholar上搜索Information Cocoons，几乎搜不到论文，寥寥几篇来自知网，引用量也极少。这个概念在英文世界基本上是一个不再活跃的概念，原因也很简单，在推荐引擎时代，我们已经不可能再面对一个自己能够完全把控信息来源的世界，我们对于筛选信息都已经没有控制权了，又如何还能有原始定义下的信息茧房呢？

回到文章开头，“名字不重要，重要是实质。”事实上，中文互联网上讨论的“信息茧房”，不再是指桑斯坦提出的这个概念，其实质是一种对互联网信息分发的担忧。担忧推荐引擎和社交网络收窄了个体的信息来源。

对推荐引擎收窄个体信息来源的担忧，在学界研究中叫做Filter Bubble（过滤气泡）。与之相关的另一个概念是Echo Chamber（回音室）效应，回音室假说是说社交网络可能会极化用户的固有观念。很遗憾这两个词也是造词家造出来的词，分别来自于Eli Pariser的畅销书 _The Filter Bubble_ 和桑斯坦的另一本畅销书 _Republic.com_（《网络共和国》）。起初定义也不明晰，在学术研究中现已基本确定为上述意思。

![Image 2: The Filter Bubble](https://img.orangeclk.com/information-cocoons-myth/filter-bubble.jpg)

![Image 3: Repulibc.com](https://img.orangeclk.com/information-cocoons-myth/republic-com.jpg)

[](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AE%BA%E6%96%87 "论文")论文
--------------------------------------------------------------------------------------------

那么是否存在过滤气泡和回音室现象呢？最近5年多，有多项实证研究讨论了这些问题，接下来两个月我会尝试每周介绍一篇论文。本周，我将介绍一篇2018的PNAS。对于我还不够认可的论文，我也会集中做些评述，但不会详细介绍。这一章节以后会不断补充。

_Christopher A. Bail, Lisa P. Argyle, Taylor W. Brown, John P. Bumpus, Haohan Chen, M. B. Fallin Hunzaker, Jaemin Lee, Marcus Mann, Friedolin Merhout, Alexander Volfovsky_

Proceedings of the National Academy of Sciences Sep 2018, 115 (37) 9216-9221; DOI: 10.1073/pnas.1804840115

论文作者和一家调研公司合作开展了一项试验。他们收集了1652名Twitter被试的信息，其中901人自我认同民主党，750自我认同共和党。对于共和党人，按照“与政党的紧密程度”、“对时事的关心程度”、“使用Twitter的频率”随机分为试验组和对照组，要求试验组用户关注一个试验方开发的Twitter机器人。对民主党被试也一样如此操作。但两个实验组关注的Twitter机器人是不同的。给共和党试验组的是一个民主党Twitter机器人，给民主党试验组的是一个共和党机器人。被试并不知道他们关注的Twitter机器人会发什么倾向的内容。

每个机器人每天会转发24条信息，每隔一周，试验方就会给被试发放调查问卷观察他们意识形态的变化，整个试验为期一个月。

![Image 4: 论文1-图1](https://img.orangeclk.com/information-cocoons-myth/pnas.1804840115-1.jpg)

### [](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#Twitter%E6%9C%BA%E5%99%A8%E4%BA%BA%E7%9A%84%E8%BD%AC%E5%8F%91%E6%9C%BA%E5%88%B6 "Twitter机器人的转发机制")Twitter机器人的转发机制

这些机器人会转发哪些帖子呢？试验方是这么设计的：

他们首先找到当时美国的当选官员和总统候选人Twitter账号，然后把这些账号所关注的账号都找出来，总共是636738个账号。把这些账号中粉丝数低于15的账号去掉，把政府账号、国际组织账号、企业账号等机构账号也都去掉，希望保留下来的尽量是个人账号，这样剩下来4176个。

以邻接矩阵的形式记录这些账号构成的网络，对这个临界矩阵做相关性分析（Correspondence Analysis），再把各个账号的粉丝数放到相关性分析的结果里，再对这个处理之后的相关性分析做一个主成分分析（Principal component analysis），这样就能够用主成分给每一个Twitter账号的政治光谱评分。如果将评分划分为1-7的区间，则民主党机器人会在1-3的账号中选择账号内容来转发，而共和党机器人会在5-7的账号内容中选择账号来转发。选择遵从正态分布。

![Image 5: 论文1-图2](https://img.orangeclk.com/information-cocoons-myth/pnas.1804840115-2.jpg)

### [](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%A2%AB%E8%AF%95%E9%85%8D%E5%90%88%E5%BA%A6 "被试配合度")被试配合度

试验还设计了对被试的配合度检测，试验方每周会选择一张可爱的动物图片，Twitter机器人每天会转发两次这张图片，并且会很快把转发删掉。每周的问卷调查都会询问被试哪张可爱的动物图片是机器人当周发过的，也会询问关于机器人当周发布内容的细节问题。通过这些问题，可以衡量被试对机器人的阅读情况，读得多的可以认为配合度较高。

### [](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AF%95%E9%AA%8C%E7%BB%93%E6%9E%9C "试验结果")试验结果

![Image 6: 论文1-图3](https://img.orangeclk.com/information-cocoons-myth/pnas.1804840115-3.jpg)

结论比较简单，看到异议Twitter机器人的人都更加向原有的观点极化，看得越多极化越多。换句话说，如果我们处在“回音室”中，在社交网络上只关注和自己观点相同的人，那么他们和不在“回音室”中的人相比，要更加温和而非极端。这和“回音室”的假说是不符的。

[](https://www.orangeclk.com/2021/06/07/information-cocoons-myth/#%E8%AF%84%E8%BF%B0 "评述")评述
--------------------------------------------------------------------------------------------

人类有很多弱点，其中一个弱点是：希望把自己的错误归咎给他者。如果这个他者是一种不会说法不会反抗的外物，那么把责任推给它实在是一种难以回避的诱惑。从实证研究中，我们看到，推荐算法放宽了人的视野、缓解了观点极化。这和过滤气泡、回音室假说不符。

陈昌凤老师在国家社科基金重大项目“智能时代的信息价值观引领研究”的阶段性成果论文中对“信息茧房”有相当完整的剖析，论文名为《“信息茧房”在中国：望文生义的概念与算法的破茧求解》。

> 桑斯坦提出的“信息茧房”，是基于美国两党政治的语境对新技术降低政治信息多元化以及政治信息极化的忧虑，但如今被剥离了美国语境、两党政争的语境，被泛用于所有信息。即使在西方，也尚缺少实证“信息茧房”存在的有力研究。

> 相比较而言，在中国，对于“信息茧房”的质疑和批判性研究很少、实证性罕见、全盘接受或望文生义的**概念化**研究却比较多，并且算法平台实务界与学术界的观点大相径庭。

> 自从桑斯坦的相关观点被介绍到国内、特别是2008年《信息乌托邦》中文译本问世之后，国内关注和使用“信息茧房”一词的文献与日俱增，尤其是大量的媒体文章中，近年把它与算法推荐、智能分发乃至社交媒体、新媒体等主观地捆绑为因果关系。

> 知网引用率最高的一篇关于“信息茧房”的文献，是《新闻前哨》编辑部梁锋的《信息茧房》，这篇文章对“信息茧房”的介绍**阐释清楚，但仅1页纸的篇幅，就被引94次**（截止到2019年12月1日）。由此可见中国学界对“信息茧房”运用的需求量和相关运用的概念化。这个形象的**比喻**易于被使用。

老师行文十分客气。

全球专业学者对这个问题的研究结果基本一致，对现状也很清醒。但也有一些专家不太跟得上研究进展，或者说是本职工作不在这一块，只是出于兴趣了解，他们的误解比较多。公众也存在一定误解。而且这种误解的表达声量较大。

这种误解甚至有可能会影响到监管决策，如果立法参考了错误的研究成果，错误的监管框架可能会让中国的相关行业无法发挥社会价值。

总会觉得没有新工具、没有互联网的世界更美好，对过去有一种“滤镜”，这是一种止步不前的懒惰视角。需要用面向未来的视角看待新事物，不要用任何过去的东西做类比，从零开始分析新事物，认真衡量它的好处和危险，然后去塑造它的发展方向。

以“信息茧房”为例，在推荐引擎出现前后，人的信息摄取是从宽变窄还是从窄变宽？从过去到未来，以这个角度观察，才有意义。如果抱着10年前20年前的场景说，现在和以前不一样，我们要恢复到以前的标杆，那恐怕是刻舟求剑。过往既不是标杆，而且也不可能再回去，必须要认真对待新事物，分析它的好处与坏处，再得出妥帖的监管策略。

[![Image 7: 知识共享许可协议](https://www.orangeclk.com/img/cc-by-sa.svg)](http://creativecommons.org/licenses/by-sa/4.0/)

本作品采用[知识共享署名-相同方式共享 4.0 国际许可协议](http://creativecommons.org/licenses/by-sa/4.0/)进行许可。

