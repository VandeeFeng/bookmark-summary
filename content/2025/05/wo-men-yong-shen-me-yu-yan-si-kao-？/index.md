---
title: 我们用什么语言思考？
date: 2025-05-26
extra:
  source: https://sspai.com/post/99441
  original_title: 我们用什么语言思考？
---
## Summary

## Full Content
Title: 我们用什么语言思考？ - 少数派

URL Source: https://sspai.com/post/99441

Published Time: 2025-05-22T06:55:10.000Z

Markdown Content:

在许多科幻作品中，读心术总是能读到清晰完整的句子，仿佛思考就是内心独白。但现实并非如此。我们常常明明知道自己在想什么，却怎么也说不出来。

这种现象引发了一个根本问题：**在尚未说出口之前，那些「已经想清楚」的内容，到底以什么形式存在？**

语言学家史蒂文·平克认为，人类思维可能依赖一种我们无法直接察觉的内部系统——「思维语」（Language of Thought）1

Pinker, Steven. The Language Instinct: How the Mind Creates Language. Harper Perennial Modern Classics, 2007.

。它不是中文，也不是英文，而是一种更深层的认知结构，用于支撑推理、判断与想象。

思维语主要用来干嘛？
----------

世界不断变化，旧经验无法应对新问题，因为旧经验有限，新问题往往无穷且难以预测。

从这点来看，我们的智能不在于记住什么，**而在于如何从已知推导未知，**在陌生情境中做出判断，生成新的想法。

如果我们想活得更好，我们必须有一种高效的无限组合能力，只要掌握了基本概念和规则，即可理解无数新情境。

试想，要理解「兔子在奔跑」，若每个场景都需单独学习，我们就得记住「兔子」「奔跑」甚至「兔子在奔跑」这个场景，更别说别的动物和场景：「狗在跑」「猫在跑」「兔子在吃」……名词和动词一多，学习量便成倍激增，认知负担极大。

但我们的思维并非如此运作。**我们能直接理解这些组合**：猫狗是相似的动物，跑是动作，可能是逃避危险。这么说来，理解发生在语言之前，语言只是用来说出来，让别人知道我们看到了什么。

![Image 14](https://cdnfile.sspai.com/2025/05/21/article/133bc7de981ae607adb5748ecd564008.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1/format/webp)
更重要的是，这种组合能力还能向抽象迁移——我们不只理解「猫在房间里」，也能用「在……里面」来理解「拥有」的关系，比如「这个人心里有个秘密」。正是这种迁移，**让我们能用有限经验适应无限变化，这就是思维语最有用的地方。**

所以我们才常有「明明知道，却说不出来」的感觉——**思维比语言快，也更高效。**语言是表达工具，而思维语才是我们真正的推理系统，就像计算机处理数据，而显示器只是输出界面。

为什么我们的语言，不适合做「思维语」？
-------------------

我们常以为自己是在「用语言思考」，但越来越多证据显示，语言其实是思维的产物，而非载体。

**首先，语言是为社交交流，而非逻辑推理设计的。**它包含大量与推理无关的信息——语序、语调、修辞格式——这些对思维反而构成噪音。语言像是一套表演脚本，需要考虑听众反应、注意力分配和情感共鸣，这些对推理都是干扰。

**其次，语言存在根本性的模糊。**「窗」可能指窗户、窗玻璃或窗口期；「bank」既可是银行也可是河岸。而我们之所以能理解这类多义词，是因为大脑默默启动了一套复杂的「歧义消解系统」，这套系统必须事先区分同一词语下的不同概念，如果语言就是思维本身，则无法解释我们如何完成这种精密推理。

**更有力的证据是，思维常发生在语言之外。**狗听得懂「去拿球」，却不会造句；婴儿不会说话，却知道什么东西掉下去会响；爱因斯坦也曾表示，他进行科学思考时主要使用的是可以随意组合的视觉图像，而非语言。

你自己也经历过「知道想表达什么但找不到词」的状态，但你不会停止思考，而是会换种说法，或用隐喻，甚至创造个新词。这些都表明思维先于语言存在。

![Image 15](https://cdnfile.sspai.com/2025/05/21/article/05f30fba44e8c1792c8a6d27ac4c20f2.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1/format/webp)
思维语在结构上既比自然语言更简单（无需冠词、发音、修辞等交际要素），又更丰富（能准确区分自然语言中模糊的概念）。**从认知演化视角看，思维语更类似于计算，我们说的语言仅是结果的注释，是思维语的不完美投影。**

「思维语」到底存不存在？能证明吗？
-----------------

思维语的存在，一直难以证明。如果它确实存在，为何我们无法直接感知它？

这一难题源于思维语的特殊性质。我们无法「看见」它，就像眼睛无法看到自己。它是观察行为本身赖以运行的系统。

这种不可感知引发了一连串哲学疑问：也许真有一套统一的「内在语言」承载我们的想法，但我们既不能控制它，也不能唤起它，更无法将它准确翻译成我们平常所说的话。

哲学家莱尔提出质疑 2

Ryle, Gilbert. The Concept of Mind. University of Chicago Press, 1949.

：所谓「在心里想」可能只是描述「尚未外化行为」的方式，思考本身就是行为的一部分。从这个角度看，「内在语言」可能只是一种幻觉，是我们所说的语言在心中留下的回音。

维特根斯坦则从另一视角提出挑战 3

Wittgenstein, Ludwig. Philosophical Investigations. Translated by G.E.M. Anscombe, Blackwell, 1953.

：如果思维语真存在，它必然是一种「私有语言」——仅你自己使用，他人无法理解。但这就陷入了矛盾：**一种无法被他人理解、不用于交流、没有公共验证规则的符号系统，还能被称为「语言」吗？**

![Image 16](https://cdnfile.sspai.com/2025/05/21/article/018bf893a79acd22908d1d5df57b51c8.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1/format/webp)
或许，我们不该把它当作语言本身，而是把它理解为**一种隐含的认知结构**：类似物理学中的「重力」，虽然看不见，但能用它来解释大量现象。

我们无法直接证明思维语存在，但它可能是我们目前**最合理的一种推断。**

大模型可以作为一种证据吗？
-------------

大模型为这一推断提供了部分间接证据。它们虽非人类思维的完美复制，却可能模拟了某些核心特性，成为观察**思维如何运作**的独特窗口。

若思维语存在，它应具备两个关键证据：**跨语言共通性和存在目的。**我们先看第一个。

### 第一个证据：跨语言共通性

表面上，世界上的语言千差万别；但在深层结构上却高度一致。超过 87%4

Crystal, David. The Cambridge Encyclopedia of Language. 2nd ed., Cambridge University Press, 1997.

的语言采用主语优先（主谓宾/主宾谓）结构，这显示人类普遍以「谁对谁做了什么」来组织思维，可能暗示着一种共同的认知基础。

Anthropic 的研究 5

Anthropic. “Tracing the Thoughts of a Large Language Model.” Anthropic, 27 Mar. 2025, [https://www.anthropic.com/research/tracing-thoughts-language-model.](https://sspai.com/link?target=https%3A%2F%2Fwww.anthropic.com%2Fresearch%2Ftracing-thoughts-language-model.)

印证了这一点：他们的 Claude 模型用中文、英文、法文回答「小的反义词是什么」这一问题。结果显示，不论使用哪种语言，模型内部都经历了相同的处理路径：**识别「反义」关系 → 理解「小」的概念 → 推导出「大」→ 再翻译成目标语言。**

![Image 17](https://cdnfile.sspai.com/2025/05/21/article/22142d54d018c1566546f15bd56092f9.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1/format/webp)
这一发现意义重大：模型的「思考」并非在语言中进行，而是在一个更深层的、语言无关的概念空间中完成，语言只是输出的包装。

Claude 激活的并不是某种语法结构，而是数、空间、意图、情绪等跨语言共享的认知维度。这表明多种语言可能通向同一个概念系统，**思考早于翻译发生。**

这也说明了：无论是 Claude 在英文中学会「反讽」并能在中文语境中正确使用，还是 GPT-3 在中文语料仅占 0.099%6

OpenAI. “Dataset Statistics.” GitHub, 2020, [https://github.com/openai/gpt-3/tree/master/dataset_statistics.【OpenAI](https://sspai.com/link?target=https%3A%2F%2Fgithub.com%2Fopenai%2Fgpt-3%2Ftree%2Fmaster%2Fdataset_statistics.%25E3%2580%2590OpenAI) 在 GPT-3 的训练数据中采用两种统计口径衡量各语言比例：按字符数计算，中文占比为 0.16012%，共计 1,828,425,488 个字符，排名第 14；按词数计算，中文占比仅为 0.09905%，共计 1,935,173,96 个词，排名第 17，这一差异反映出由于中文为非空格分词语言，字符密度高，按词数统计会显著低估其实际语料体量。】

的训练数据下，依然能流畅生成中文文本，背后的原理都是一样的——**模型捕捉到的是语言背后的概念，而非语言。**

### 第二个证据：存在目的

思维语如果真的存在，它就不仅能表达概念，还应能围绕某个目的进行思维组织。前文提到，我们的推理是为了从未知推到已知，解决遇到的问题，人类思维展现出一种天然的「目的驱动」：我们不会无意识地堆叠词句，而是围绕问题、目的、意图来组织语言和推理路径。

人们常说，大语言模型只是在**「预测下一个词」**，类似手机键盘的自动补全功能——如果一直选择最可能的下一个词，确实能产生表面连贯但内在空洞的文本 7

Bender, Emily M., et al. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT '21), Association for Computing Machinery, 2021, pp. 610–623. [https://doi.org/10.1145/3442188.3445922.【语言学家](https://sspai.com/link?target=https%3A%2F%2Fdoi.org%2F10.1145%2F3442188.3445922.%25E3%2580%2590%25E8%25AF%25AD%25E8%25A8%2580%25E5%25AD%25A6%25E5%25AE%25B6) Emily M. Bender 等人提出「随机鹦鹉」，批评大模型在生成语言时仅仅依赖统计模式，而缺乏对语言意义的真正理解 。】

。

但事实远比这复杂。Anthropic 的研究发现，Claude 在写诗时，会预先设定押韵词（如下图的**rabbit**），然后围绕这个目标构建句子。即便研究者屏蔽这个词，模型依然会重设方向并重构句子结构。

![Image 18](https://cdnfile.sspai.com/2025/05/21/article/32fed894a77183b5e3bc220bfebbfe49.png?imageView2/2/w/1120/q/40/interlace/1/ignore-error/1/format/webp)
这说明，它并不是在句尾「碰巧押韵」，**而是在生成之初就围绕一个目的组织内容。**

Claude 的这种能力暗示我们：大模型不仅是文本生成器，更可能是一种思维模拟系统。

结语
--

探索思维语的旅程让我们面对一个既古老又现代的问题：什么是思维？

在这个问题上，传统方法长期受限，我们的观察手段极为有限，大多停留在「人说某句话时脑部哪个区域活跃」这类粗糙的相关性研究上。这种局限一方面源于技术瓶颈，另一方面则是道德伦理约束——我们不能像操作机器一样打开人脑，直视思考过程。

大模型的出现打破了这一困局。它成为一个可自由操控的「思维观察室」。在这里，研究者可以进行在人类身上无法实施的实验：**修改一个概念，观察它如何重组系统；或阻断推理路径，观察模型如何寻找替代方案**8

这里指文中提及的 Claude 可解释性研究，研究人员通过操控模型内部的中间概念路径（例如将「Texas」替换为「California」），观察 Claude 如何将答案从「Austin」更新为「Sacramento」，从而验证模型是在进行多步推理而非死记硬背。

。

正是在这些超越人类伦理边界的操作中，思维语这个本难以验证的假说，开始显现出某种可被观测的迹象。在我们表达的语言之下，或许真的存在一种更抽象、更基础的符号系统，它既是思维的媒介，也是智能的底层结构。

或许未来，我们不再只是用语言理解模型，而是借助模型，反过来理解语言，理解我们自己。

本文首发[言辞之间](https://mp.weixin.qq.com/s/Svd2idHxQ1dL91GNI1BtoA)，同步少数派。

> 关注[少数派小红书](https://www.xiaohongshu.com/user/profile/63f5d65d000000001001d8d4)，感受精彩数字生活 🍃

> 实用、好用的 [正版软件](https://sspai.com/mall)，少数派为你呈现 🚀

*   1 Pinker, Steven. The Language Instinct: How the Mind Creates Language. Harper Perennial Modern Classics, 2007.
*   2 Ryle, Gilbert. The Concept of Mind. University of Chicago Press, 1949.
*   3 Wittgenstein, Ludwig. Philosophical Investigations. Translated by G.E.M. Anscombe, Blackwell, 1953.
*   4 Crystal, David. The Cambridge Encyclopedia of Language. 2nd ed., Cambridge University Press, 1997.
*   5 Anthropic. “Tracing the Thoughts of a Large Language Model.” Anthropic, 27 Mar. 2025, https://www.anthropic.com/research/tracing-thoughts-language-model.
*   6 OpenAI. “Dataset Statistics.” GitHub, 2020, https://github.com/openai/gpt-3/tree/master/dataset_statistics.【OpenAI 在 GPT-3 的训练数据中采用两种统计口径衡量各语言比例：按字符数计算，中文占比为 0.16012%，共计 1,828,425,488 个字符，排名第 14；按词数计算，中文占比仅为 0.09905%，共计 1,935,173,96 个词，排名第 17，这一差异反映出由于中文为非空格分词语言，字符密度高，按词数统计会显著低估其实际语料体量。】
*   7 Bender, Emily M., et al. “On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?” Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT '21), Association for Computing Machinery, 2021, pp. 610–623. https://doi.org/10.1145/3442188.3445922.【语言学家 Emily M. Bender 等人提出「随机鹦鹉」，批评大模型在生成语言时仅仅依赖统计模式，而缺乏对语言意义的真正理解 。】
*   8 这里指文中提及的 Claude 可解释性研究，研究人员通过操控模型内部的中间概念路径（例如将「Texas」替换为「California」），观察 Claude 如何将答案从「Austin」更新为「Sacramento」，从而验证模型是在进行多步推理而非死记硬背。

